{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abfb468",
   "metadata": {},
   "source": [
    "# Causal mediation analysis \n",
    "\n",
    "The objective of this notebook is to develop a basic understanding of causal mediation analysis on a toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a98b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import cluster, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e59dd",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23644e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(170)\n",
    "\n",
    "### Create dataset features\n",
    "\n",
    "n_samples = 10000\n",
    "X, l = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=170)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ffb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot options\n",
    "\n",
    "colors = np.array(\n",
    "    list(\n",
    "        islice(\n",
    "            cycle(\n",
    "                [\n",
    "                    \"#377eb8\",\n",
    "                    \"#ff7f00\",\n",
    "                    \"#4daf4a\",\n",
    "                    \"#f781bf\",\n",
    "                    \"#a65628\",\n",
    "                    \"#984ea3\",\n",
    "                    \"#999999\",\n",
    "                    \"#e41a1c\",\n",
    "                    \"#dede00\",\n",
    "                ]\n",
    "            ),\n",
    "            int(max(l) + 1),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "markers = np.array(\n",
    "    list(\n",
    "        islice(\n",
    "            cycle(\n",
    "                [\n",
    "                    \".\",\n",
    "                    \"+\",\n",
    "                    \"x\",\n",
    "                    \"v\",\n",
    "                    \"s\",\n",
    "                    \"p\",\n",
    "                ]\n",
    "            ),\n",
    "            int(max(l) + 1),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a2752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Dataset visualisation\n",
    "\n",
    "reg = LogisticRegression().fit(X, l)\n",
    "l_fitted = reg.predict(X)\n",
    "l_fitted\n",
    "markers = np.array(['.', '+'], dtype=str)\n",
    "labels = ['nonsocial', 'social']\n",
    "\n",
    "# plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_fitted], marker=markers[y])\n",
    "for i, c in enumerate(np.unique(l)):\n",
    "    plt.scatter(X[:,0][l==c],X[:,1][l==c],color=colors[l_fitted][l==c], marker=markers[i], label=labels[i])\n",
    "    \n",
    "plt.plot()\n",
    "plt.xlim(-1.5, 2.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('noisymoons')\n",
    "plt.legend()\n",
    "plt.savefig('noisymoons.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d8284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatments and other quantities\n",
    "\n",
    "T = rng.choice([0,1], size=(n_samples,1))\n",
    "np.mean(X, axis=0)\n",
    "#mean_X = np.array([0.5, 0.25])\n",
    "mean_X = np.array([0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c590f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "\n",
    "reg = LinearRegression().fit(X, l)\n",
    "reg.score(X, l), reg.coef_, reg.intercept_\n",
    "beta_0 = reg.intercept_\n",
    "beta_X = reg.coef_\n",
    "\n",
    "beta_T = np.array([1])\n",
    "beta_TX = np.array([0,0])\n",
    "omega_T = 0.9\n",
    "\n",
    "M_ = beta_0 + X.dot(beta_X) + omega_T*T.dot(beta_T) + (T*X).dot(beta_TX) + rng.normal(0, 0.1, size=T.shape[0])\n",
    "M = np.expand_dims(M_, axis=-1)\n",
    "\n",
    "gamma_0 = 0\n",
    "gamma_X = np.array([0,0]) \n",
    "gamma_T = np.array([0.2])\n",
    "gamma_M = np.array([1])\n",
    "gamma_MT = np.array([0])\n",
    "omega_M = 0.9\n",
    "\n",
    "Y = gamma_0 + X.dot(gamma_X) + T.dot(gamma_T) + omega_M*M.dot(gamma_M) + (T*M).dot(gamma_MT) + rng.normal(0, 0.1, size=T.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a24af6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "((T*X).dot(beta_TX)).shape\n",
    "linear_X = beta_0 + X.dot(beta_X)\n",
    "linear_T = omega_T*T.dot(beta_T)\n",
    "linear_TX = (T*X).dot(beta_TX)\n",
    "noise = rng.normal(0, 0.1, size=T.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "811a6446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5c31a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Causal quantities\n",
    "\n",
    "mean_M_t1 = beta_0 + mean_X.dot(beta_X) + mean_X.dot(beta_TX) + omega_T *beta_T\n",
    "mean_M_t0 = beta_0 + mean_X.dot(beta_X)\n",
    "\n",
    "theta_1 = gamma_T + gamma_MT.T.dot(mean_M_t1) # to do mean(m1) pour avoir un vecteur de taille dim_m\n",
    "theta_0 = gamma_T + gamma_MT.T.dot(mean_M_t0)\n",
    "#delta_1 = (gamma_T * t1 + m1.dot(gamma_m) + m1.dot(gamma_t_m) * t1 - gamma_t * t1 + m0.dot(gamma_m) + m0.dot(gamma_t_m) * t1).mean()\n",
    "#delta_0 = (gamma_T * t0 + m1.dot(gamma_m) + m1.dot(gamma_t_m) * t0 - gamma_t * t0 + m0.dot(gamma_m) + m0.dot(gamma_t_m) * t0).mean()\n",
    "delta_1 = (mean_X.dot(beta_TX) + omega_T * beta_T) * (omega_M * gamma_M + gamma_MT)\n",
    "delta_0 = (mean_X.dot(beta_TX) + omega_T * beta_T) * (omega_M * gamma_M)\n",
    "\n",
    "tau = gamma_T + omega_M * gamma_M * omega_T * beta_T\n",
    "tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd617ea",
   "metadata": {},
   "source": [
    "## Causal effect estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa63c8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CV_FOLDS = 5\n",
    "ALPHAS = np.logspace(-5, 5, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5768c8",
   "metadata": {},
   "source": [
    "### Importance weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfdb2b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(regularization=False, forest=False, calibration=True, calib_method='sigmoid'):\n",
    "    if regularization:\n",
    "        cs = ALPHAS\n",
    "    else:\n",
    "        cs = [np.inf]\n",
    "        \n",
    "    if not forest:\n",
    "        x_clf = LogisticRegressionCV(Cs=cs, cv=CV_FOLDS)\n",
    "        xm_clf = LogisticRegressionCV(Cs=cs, cv=CV_FOLDS)\n",
    "    else:\n",
    "        x_clf = RandomForestClassifier(n_estimators=100,\n",
    "                                              min_samples_leaf=10)\n",
    "        xm_clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=10)\n",
    "    if calibration:\n",
    "        x_clf = CalibratedClassifierCV(x_clf,\n",
    "                                         method=calib_method)\n",
    "        xm_clf = CalibratedClassifierCV(xm_clf, method=calib_method)\n",
    "            \n",
    "    return x_clf, xm_clf\n",
    "    \n",
    "def get_train_test_lists(crossfit, n): \n",
    "    if crossfit < 2:\n",
    "        train_test_list = [[np.arange(n), np.arange(n)]]\n",
    "    else:\n",
    "        kf = KFold(n_splits=crossfit)\n",
    "        train_test_list = list()\n",
    "        for train_index, test_index in kf.split(x):\n",
    "            train_test_list.append([train_index, test_index])\n",
    "    return train_test_list\n",
    "\n",
    "def estimate_probabilities(t, m, x, crossfit, classifier_x, classifier_xm):\n",
    "    \n",
    "    n = len(t)\n",
    "    train_test_list = [[np.arange(n), np.arange(n)]]\n",
    "    \n",
    "    p_x, p_xm = [np.zeros(n) for h in range(2)]\n",
    "    # compute propensity scores\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if len(m.shape) == 1:\n",
    "        m = m.reshape(-1, 1)\n",
    "    \n",
    "    train_test_list = get_train_test_lists(crossfit, n)\n",
    "    \n",
    "    for train_index, test_index in train_test_list:\n",
    "        x_clf = classifier_x.fit(x[train_index, :], t[train_index])\n",
    "        xm_clf = classifier_xm.fit(np.hstack((x, m))[train_index, :], t[train_index])\n",
    "        p_x[test_index] = x_clf.predict_proba(x[test_index, :])[:, 1]\n",
    "        p_xm[test_index] = xm_clf.predict_proba(\n",
    "            np.hstack((x, m))[test_index, :])[:, 1]\n",
    "        \n",
    "    return p_x, p_xm\n",
    "\n",
    "def SNIPW(y, t, m, x, trim, p_x, p_xm):\n",
    "    \"\"\"\n",
    "    IPW estimator presented in\n",
    "    HUBER, Martin. Identifying causal mechanisms (primarily) based on inverse\n",
    "    probability weighting. Journal of Applied Econometrics, 2014,\n",
    "    vol. 29, no 6, p. 920-943.\n",
    "\n",
    "    results has 6 values\n",
    "    - total effect\n",
    "    - direct effect treated (\\theta(1))\n",
    "    - direct effect non treated (\\theta(0))\n",
    "    - indirect effect treated (\\delta(1))\n",
    "    - indirect effect untreated (\\delta(0))\n",
    "    - number of used observations (non trimmed)\n",
    "\n",
    "    y       array-like, shape (n_samples)\n",
    "            outcome value for each unit, continuous\n",
    "\n",
    "    t       array-like, shape (n_samples)\n",
    "            treatment value for each unit, binary\n",
    "\n",
    "    m       array-like, shape (n_samples, n_features_mediator)\n",
    "            mediator value for each unit, can be continuous or binary, and\n",
    "            multi-dimensional\n",
    "\n",
    "    x       array-like, shape (n_samples, n_features_covariates)\n",
    "            covariates (potential confounders) values\n",
    "\n",
    "\n",
    "    trim    float\n",
    "            Trimming rule for discarding observations with extreme propensity\n",
    "            scores. In the absence of post-treatment confounders (w=NULL),\n",
    "            observations with Pr(D=1|M,X)<trim or Pr(D=1|M,X)>(1-trim) are\n",
    "            dropped. In the presence of post-treatment confounders\n",
    "            (w is defined), observations with Pr(D=1|M,W,X)<trim or\n",
    "            Pr(D=1|M,W,X)>(1-trim) are dropped.\n",
    "\n",
    "    logit   boolean\n",
    "            whether logit or pobit regression is used for propensity score\n",
    "            legacy from the R package, here only logit is implemented\n",
    "\n",
    "    regularization boolean, default True\n",
    "                   whether to use regularized models (logistic or\n",
    "                   linear regression). If True, cross-validation is used\n",
    "                   to chose among 8 potential log-spaced values between\n",
    "                   1e-5 and 1e5\n",
    "\n",
    "    forest  boolean, default False\n",
    "            whether to use a random forest model to estimate the propensity\n",
    "            scores instead of logistic regression\n",
    "\n",
    "    crossfit integer, default 0\n",
    "             number of folds for cross-fitting\n",
    "\n",
    "    clip    float\n",
    "            limit to clip for numerical stability (min=clip, max=1-clip)\n",
    "    \"\"\"\n",
    "\n",
    "    # trimming. Following causal weight code, not sure I understand\n",
    "    # why we trim only on p_xm and not on p_x\n",
    "    ind = ((p_xm > trim) & (p_xm < (1 - trim)))\n",
    "    y, t, p_x, p_xm = y[ind], t[ind], p_x[ind], p_xm[ind]\n",
    "\n",
    "    # note on the names, ytmt' = Y(t, M(t')), the treatment needs to be\n",
    "    # binary but not the mediator\n",
    "    p_x = np.clip(p_x, clip, 1 - clip)\n",
    "    p_xm = np.clip(p_xm, clip, 1 - clip)\n",
    "\n",
    "    y1m1 = np.sum(y * t / p_x) / np.sum(t / p_x)\n",
    "    y1m0 = np.sum(y * t * (1 - p_xm) / (p_xm * (1 - p_x))) /\\\n",
    "        np.sum(t * (1 - p_xm) / (p_xm * (1 - p_x)))\n",
    "    y0m0 = np.sum(y * (1 - t) / (1 - p_x)) /\\\n",
    "        np.sum((1 - t) / (1 - p_x))\n",
    "    y0m1 = np.sum(y * (1 - t) * p_xm / ((1 - p_xm) * p_x)) /\\\n",
    "        np.sum((1 - t) * p_xm / ((1 - p_xm) * p_x))\n",
    "\n",
    "    return(y1m1 - y0m0,\n",
    "           y1m1 - y0m1,\n",
    "           y1m0 - y0m0,\n",
    "           y1m1 - y1m0,\n",
    "           y0m1 - y0m0,\n",
    "           np.sum(ind))\n",
    "\n",
    "def IPW(y, t, m, x, trim, p_x, p_xm):\n",
    "    \"\"\"\n",
    "    IPW estimator presented in\n",
    "    HUBER, Martin. Identifying causal mechanisms (primarily) based on inverse\n",
    "    probability weighting. Journal of Applied Econometrics, 2014,\n",
    "    vol. 29, no 6, p. 920-943.\n",
    "\n",
    "    results has 6 values\n",
    "    - total effect\n",
    "    - direct effect treated (\\theta(1))\n",
    "    - direct effect non treated (\\theta(0))\n",
    "    - indirect effect treated (\\delta(1))\n",
    "    - indirect effect untreated (\\delta(0))\n",
    "    - number of used observations (non trimmed)\n",
    "\n",
    "    y       array-like, shape (n_samples)\n",
    "            outcome value for each unit, continuous\n",
    "\n",
    "    t       array-like, shape (n_samples)\n",
    "            treatment value for each unit, binary\n",
    "\n",
    "    m       array-like, shape (n_samples, n_features_mediator)\n",
    "            mediator value for each unit, can be continuous or binary, and\n",
    "            multi-dimensional\n",
    "\n",
    "    x       array-like, shape (n_samples, n_features_covariates)\n",
    "            covariates (potential confounders) values\n",
    "\n",
    "\n",
    "    trim    float\n",
    "            Trimming rule for discarding observations with extreme propensity\n",
    "            scores. In the absence of post-treatment confounders (w=NULL),\n",
    "            observations with Pr(D=1|M,X)<trim or Pr(D=1|M,X)>(1-trim) are\n",
    "            dropped. In the presence of post-treatment confounders\n",
    "            (w is defined), observations with Pr(D=1|M,W,X)<trim or\n",
    "            Pr(D=1|M,W,X)>(1-trim) are dropped.\n",
    "\n",
    "    logit   boolean\n",
    "            whether logit or pobit regression is used for propensity score\n",
    "            legacy from the R package, here only logit is implemented\n",
    "\n",
    "    regularization boolean, default True\n",
    "                   whether to use regularized models (logistic or\n",
    "                   linear regression). If True, cross-validation is used\n",
    "                   to chose among 8 potential log-spaced values between\n",
    "                   1e-5 and 1e5\n",
    "\n",
    "    forest  boolean, default False\n",
    "            whether to use a random forest model to estimate the propensity\n",
    "            scores instead of logistic regression\n",
    "\n",
    "    crossfit integer, default 0\n",
    "             number of folds for cross-fitting\n",
    "\n",
    "    clip    float\n",
    "            limit to clip for numerical stability (min=clip, max=1-clip)\n",
    "    \"\"\"\n",
    "\n",
    "    # trimming. Following causal weight code, not sure I understand\n",
    "    # why we trim only on p_xm and not on p_x\n",
    "    ind = ((p_xm > trim) & (p_xm < (1 - trim)))\n",
    "    y, t, p_x, p_xm = y[ind], t[ind], p_x[ind], p_xm[ind]\n",
    "\n",
    "    # note on the names, ytmt' = Y(t, M(t')), the treatment needs to be\n",
    "    # binary but not the mediator\n",
    "    p_x = np.clip(p_x, clip, 1 - clip)\n",
    "    p_xm = np.clip(p_xm, clip, 1 - clip)\n",
    "\n",
    "    y1m1 = np.mean(y * t / p_x) \n",
    "    y1m0 = np.mean(y * t * (1 - p_xm) / (p_xm * (1 - p_x))) \n",
    "    y0m0 = np.mean(y * (1 - t) / (1 - p_x)) \n",
    "    y0m1 = np.mean(y * (1 - t) * p_xm / ((1 - p_xm) * p_x)) \n",
    "\n",
    "    return(y1m1 - y0m0,\n",
    "           y1m1 - y0m1,\n",
    "           y1m0 - y0m0,\n",
    "           y1m1 - y1m0,\n",
    "           y0m1 - y0m0,\n",
    "           np.sum(ind))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf795077",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Y\n",
    "t = T\n",
    "m = M\n",
    "x = X\n",
    "trim=0\n",
    "logit=True\n",
    "regularization=False\n",
    "forest=False\n",
    "crossfit=0\n",
    "clip=0.0\n",
    "calibration=False\n",
    "classifier_x, classifier_xm = get_classifier(regularization, forest, calibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60063b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "p_x, p_xm = estimate_probabilities(t, m, x, crossfit, classifier_x, classifier_xm)\n",
    "effects_IPW = IPW(y, t, m, x, trim, p_x, p_xm)\n",
    "effects_SNIPW = SNIPW(y, t, m, x, trim, p_x, p_xm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6e0cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_hat, theta_1_hat, theta_0_hat, delta_1_hat, delta_0_hat, n_non_trimmed = effects_IPW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69e45369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPW\n",
      "Direct effects\n",
      "True theta1:[0.2], estimated theta1: -478403411903829.6\n",
      "True theta0:[0.2], estimated theta0: -5.960267411051258e+25\n",
      "\\\n",
      "Indirect effects\n",
      "True delta1:[0.81], estimated delta1: 5.960267411051258e+25\n",
      "True delta0:[0.81], estimated delta0: 478403411903829.1\n",
      "\\\n",
      "Total effect\n",
      "True tau:[1.01], estimated tau: -0.489\n"
     ]
    }
   ],
   "source": [
    "print(\"IPW\")\n",
    "print(\"Direct effects\")\n",
    "print(\"True theta1:{}, estimated theta1: {}\".format(theta_1, round(theta_1_hat,3)))\n",
    "print(\"True theta0:{}, estimated theta0: {}\".format(theta_0, round(theta_0_hat,3)))\n",
    "print(\"\\\\\")\n",
    "print(\"Indirect effects\")\n",
    "print(\"True delta1:{}, estimated delta1: {}\".format(delta_1, round(delta_1_hat,3)))\n",
    "print(\"True delta0:{}, estimated delta0: {}\".format(delta_0, round(delta_0_hat,3)))\n",
    "print(\"\\\\\")\n",
    "print(\"Total effect\")\n",
    "print(\"True tau:{}, estimated tau: {}\".format(tau, round(tau_hat,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5ad6863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNIPW\n",
      "Direct effects\n",
      "True theta1:[0.2], estimated theta1: -0.694\n",
      "True theta0:[0.2], estimated theta0: -0.903\n",
      "\\\n",
      "Indirect effects\n",
      "True delta1:[0.81], estimated delta1: 0.893\n",
      "True delta0:[0.81], estimated delta0: 0.684\n",
      "\\\n",
      "Total effect\n",
      "True tau:[1.01], estimated tau: -0.01\n"
     ]
    }
   ],
   "source": [
    "tau_hat, theta_1_hat, theta_0_hat, delta_1_hat, delta_0_hat, n_non_trimmed = effects_SNIPW\n",
    "print(\"SNIPW\")\n",
    "print(\"Direct effects\")\n",
    "print(\"True theta1:{}, estimated theta1: {}\".format(theta_1, round(theta_1_hat,3)))\n",
    "print(\"True theta0:{}, estimated theta0: {}\".format(theta_0, round(theta_0_hat,3)))\n",
    "print(\"\\\\\")\n",
    "print(\"Indirect effects\")\n",
    "print(\"True delta1:{}, estimated delta1: {}\".format(delta_1, round(delta_1_hat,3)))\n",
    "print(\"True delta0:{}, estimated delta0: {}\".format(delta_0, round(delta_0_hat,3)))\n",
    "print(\"\\\\\")\n",
    "print(\"Total effect\")\n",
    "print(\"True tau:{}, estimated tau: {}\".format(tau, round(tau_hat,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5147842",
   "metadata": {},
   "source": [
    "### Ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_mediation(y, t, m, x, interaction=False, regularization=True):\n",
    "    \"\"\"\n",
    "    found an R implementation https://cran.r-project.org/package=regmedint\n",
    "\n",
    "    implements very simple model of mediation\n",
    "    Y ~ X + T + M\n",
    "    M ~ X + T\n",
    "    estimation method is product of coefficients\n",
    "\n",
    "    y       array-like, shape (n_samples)\n",
    "            outcome value for each unit, continuous\n",
    "\n",
    "    t       array-like, shape (n_samples)\n",
    "            treatment value for each unit, binary\n",
    "\n",
    "    m       array-like, shape (n_samples)\n",
    "            mediator value for each unit, can be continuous or binary, and\n",
    "            is necessary in 1D\n",
    "\n",
    "    x       array-like, shape (n_samples, n_features_covariates)\n",
    "            covariates (potential confounders) values\n",
    "\n",
    "    interaction boolean, default=False\n",
    "                whether to include interaction terms in the model\n",
    "                not implemented here, just for compatibility of signature\n",
    "                function\n",
    "\n",
    "    regularization boolean, default True\n",
    "                   whether to use regularized models (logistic or\n",
    "                   linear regression). If True, cross-validation is used\n",
    "                   to chose among 8 potential log-spaced values between\n",
    "                   1e-5 and 1e5\n",
    "\n",
    "    \"\"\"\n",
    "    if regularization:\n",
    "        alphas = ALPHAS\n",
    "    else:\n",
    "        alphas = [0.0]\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if len(m.shape) == 1:\n",
    "        m = m.reshape(-1, 1)\n",
    "    if len(t.shape) == 1:\n",
    "        t = t.reshape(-1, 1)\n",
    "    coef_t_m = np.zeros(m.shape[1])\n",
    "    for i in range(m.shape[1]):\n",
    "        m_reg = RidgeCV(alphas=alphas, cv=CV_FOLDS)\\\n",
    "            .fit(np.hstack((x, t)), m[:, i])\n",
    "        coef_t_m[i] = m_reg.coef_[-1]\n",
    "    y_reg = RidgeCV(alphas=alphas, cv=CV_FOLDS)\\\n",
    "        .fit(np.hstack((x, t, m)), y.ravel())\n",
    "\n",
    "    # return total, direct and indirect effect\n",
    "    direct_effect = y_reg.coef_[x.shape[1]]\n",
    "    indirect_effect = sum(y_reg.coef_[x.shape[1] + 1:] * coef_t_m)\n",
    "    return [direct_effect + indirect_effect,\n",
    "            direct_effect,\n",
    "            direct_effect,\n",
    "            indirect_effect,\n",
    "            indirect_effect,\n",
    "            None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d8c15b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regressions(regularization=False, interaction=False, forest=False, calibration=True, calib_method='sigmoid'):\n",
    "    if regularization:\n",
    "        cs = ALPHAS\n",
    "    else:\n",
    "        cs = [np.inf]\n",
    "        \n",
    "    # mu_tm, f_mtx, and p_x model fitting\n",
    "    if not forest:\n",
    "        y_reg = RidgeCV(alphas=alphas, cv=CV_FOLDS)\n",
    "        pre_m_prob = LogisticRegressionCV(Cs=cs, cv=CV_FOLDS).fit(\n",
    "            get_interactions(interaction, t, x)[train_index, :], m[train_index]\n",
    "        )\n",
    "        pre_p_x_clf = LogisticRegressionCV(Cs=cs, cv=CV_FOLDS).fit(\n",
    "            x[train_index, :], t[train_index]\n",
    "        )\n",
    "    else:\n",
    "        y_reg = RandomForestRegressor(n_estimators=100, min_samples_leaf=10)\n",
    "        pre_m_prob = RandomForestClassifier(\n",
    "            n_estimators=100, min_samples_leaf=10\n",
    "        )\n",
    "        pre_p_x_clf = RandomForestClassifier(\n",
    "            n_estimators=100, min_samples_leaf=10\n",
    "        )\n",
    "    if calibration:\n",
    "        m_prob = CalibratedClassifierCV(pre_m_prob, method=calib_method)\n",
    "        p_x_clf = CalibratedClassifierCV(pre_p_x_clf, method=calib_method)\n",
    "    else:\n",
    "        m_prob = pre_m_prob\n",
    "        p_x_clf = pre_p_x_clf\n",
    "            \n",
    "    return y_reg, m_prob, p_x_clf\n",
    "    \n",
    "def get_train_test_lists(crossfit, n): \n",
    "    if crossfit < 2:\n",
    "        train_test_list = [[np.arange(n), np.arange(n)]]\n",
    "    else:\n",
    "        kf = KFold(n_splits=crossfit)\n",
    "        train_test_list = list(kf.split(x))\n",
    "        \n",
    "    return train_test_list\n",
    "\n",
    "def estimate_probabilities(t, m, x, crossfit, classifier_x, classifier_xm):\n",
    "    \n",
    "    n = len(t)\n",
    "    train_test_list = [[np.arange(n), np.arange(n)]]\n",
    "    \n",
    "    p_x, p_xm = [np.zeros(n) for h in range(2)]\n",
    "    # compute propensity scores\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.reshape(-1, 1)\n",
    "    if len(m.shape) == 1:\n",
    "        m = m.reshape(-1, 1)\n",
    "    \n",
    "    train_test_list = get_train_test_lists(crossfit, n)\n",
    "    \n",
    "    for train_index, test_index in train_test_list:\n",
    "        x_clf = classifier_x.fit(x[train_index, :], t[train_index])\n",
    "        xm_clf = classifier_xm.fit(np.hstack((x, m))[train_index, :], t[train_index])\n",
    "        p_x[test_index] = x_clf.predict_proba(x[test_index, :])[:, 1]\n",
    "        p_xm[test_index] = xm_clf.predict_proba(\n",
    "            np.hstack((x, m))[test_index, :])[:, 1]\n",
    "        \n",
    "    return p_x, p_xm\n",
    "\n",
    "def get_interactions(interaction, *args):\n",
    "    \"\"\"\n",
    "    this function provides interaction terms between different groups of\n",
    "    variables (confounders, treatment, mediators)\n",
    "    Inputs\n",
    "    --------\n",
    "    interaction     boolean\n",
    "                    whether to compute interaction terms\n",
    "\n",
    "    *args           flexible, one or several arrays\n",
    "                    blocks of variables between which interactions should be\n",
    "                    computed\n",
    "    Returns\n",
    "    --------\n",
    "    Examples\n",
    "    --------\n",
    "    >>> x = np.arange(6).reshape(3, 2)\n",
    "    >>> t = np.ones((3, 1))\n",
    "    >>> m = 2 * np.ones((3, 1))\n",
    "    >>> get_interactions(False, x, t, m)\n",
    "    array([[0., 1., 1., 2.],\n",
    "           [2., 3., 1., 2.],\n",
    "           [4., 5., 1., 2.]])\n",
    "    >>> get_interactions(True, x, t, m)\n",
    "    array([[ 0.,  1.,  1.,  2.,  0.,  1.,  0.,  2.,  2.],\n",
    "           [ 2.,  3.,  1.,  2.,  2.,  3.,  4.,  6.,  2.],\n",
    "           [ 4.,  5.,  1.,  2.,  4.,  5.,  8., 10.,  2.]])\n",
    "    \"\"\"\n",
    "    variables = list(args)\n",
    "    for index, var in enumerate(variables):\n",
    "        if len(var.shape) == 1:\n",
    "            variables[index] = var.reshape(-1,1)\n",
    "    pre_inter_variables = np.hstack(variables)\n",
    "    if not interaction:\n",
    "        return pre_inter_variables\n",
    "    new_cols = list()\n",
    "    for i, var in enumerate(variables[:]):\n",
    "        for j, var2 in enumerate(variables[i+1:]):\n",
    "            for ii in range(var.shape[1]):\n",
    "                for jj in range(var2.shape[1]):\n",
    "                    new_cols.append((var[:, ii] * var2[:, jj]).reshape(-1, 1))\n",
    "    new_vars = np.hstack(new_cols)\n",
    "    result = np.hstack((pre_inter_variables, new_vars))\n",
    "    return result\n",
    "\n",
    "def multiply_robust_efficient(\n",
    "    y,\n",
    "    t,\n",
    "    m,\n",
    "    x,\n",
    "    interaction=False,\n",
    "    forest=False,\n",
    "    crossfit=0,\n",
    "    trim=0.01,\n",
    "    regularization=True,\n",
    "    calibration=True,\n",
    "    calib_method=\"sigmoid\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Presented in Eric J. Tchetgen Tchetgen. Ilya Shpitser.\n",
    "    \"Semiparametric theory for causal mediation analysis: Efficiency bounds,\n",
    "    multiple robustness and sensitivity analysis.\"\n",
    "    Ann. Statist. 40 (3) 1816 - 1845, June 2012.\n",
    "    https://doi.org/10.1214/12-AOS990\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array-like, shape (n_samples)\n",
    "        Outcome value for each unit, continuous\n",
    "\n",
    "    t : array-like, shape (n_samples)\n",
    "        Treatment value for each unit, binary\n",
    "\n",
    "    m : array-like, shape (n_samples)\n",
    "        Mediator value for each unit, binary and unidimensional\n",
    "\n",
    "    x : array-like, shape (n_samples, n_features_covariates)\n",
    "        Covariates value for each unit, continuous\n",
    "\n",
    "    interaction : boolean, default=False\n",
    "        Whether to include interaction terms in the model\n",
    "        interactions are terms XT, TM, MX\n",
    "\n",
    "    forest : boolean, default=False\n",
    "        Whether to use a random forest model to estimate the propensity\n",
    "        scores instead of logistic regression, and outcome model instead\n",
    "        of linear regression\n",
    "\n",
    "    crossfit : integer, default=0\n",
    "        Number of folds for cross-fitting. If crossfit<2, no cross-fitting is applied\n",
    "\n",
    "    trim : float, default=0.01\n",
    "        Limit to trim p_x and f_mtx for numerical stability (min=trim, max=1-trim)\n",
    "\n",
    "    regularization : boolean, default=True\n",
    "        Whether to use regularized models (logistic or linear regression).\n",
    "        If True, cross-validation is used to chose among 8 potential\n",
    "        log-spaced values between 1e-5 and 1e5\n",
    "\n",
    "    calibration : boolean, default=True\n",
    "        Whether to add a calibration step so that the classifier used to estimate\n",
    "        the treatment propensity score and the density of the (binary) mediator.\n",
    "        Calibration ensures the output of the [predict_proba](https://scikit-learn.org/stable/glossary.html#term-predict_proba)\n",
    "        method can be directly interpreted as a confidence level.\n",
    "\n",
    "    calib_method : str, default=\"sigmoid\"\n",
    "        Which calibration method to use.\n",
    "        Implemented calibration methods are \"sigmoid\" and \"isotonic\".\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    total : float\n",
    "        Average total effect.\n",
    "    direct1 : float\n",
    "        Direct effect on the exposed.\n",
    "    direct0 : float\n",
    "        Direct effect on the unexposed,\n",
    "    indirect1 : float\n",
    "        Indirect effect on the exposed.\n",
    "    indirect0 : float\n",
    "        Indirect effect on the unexposed.\n",
    "    n_discarded : int\n",
    "        Number of discarded samples due to trimming.\n",
    "\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        - If t or y are multidimensional.\n",
    "        - If x, t, m, or y don't have the same length.\n",
    "        - If m is not binary.\n",
    "    \"\"\"\n",
    "    # Format checking\n",
    "    if len(y) != len(y.ravel()):\n",
    "        raise ValueError(\"Multidimensional y is not supported\")\n",
    "    if len(t) != len(t.ravel()):\n",
    "        raise ValueError(\"Multidimensional t is not supported\")\n",
    "    if len(m) != len(m.ravel()):\n",
    "        raise ValueError(\"Multidimensional m is not supported\")\n",
    "\n",
    "    n = len(y)\n",
    "    if len(x.shape) == 1:\n",
    "        x.reshape(n, 1)\n",
    "    if len(m.shape) == 1:\n",
    "        m.reshape(n, 1)\n",
    "\n",
    "    dim_m = m.shape[1]\n",
    "    if n * dim_m != sum(m.ravel() == 1) + sum(m.ravel() == 0):\n",
    "        raise ValueError(\"m is not binary\")\n",
    "\n",
    "    y = y.ravel()\n",
    "    t = t.ravel()\n",
    "    m = m.ravel()\n",
    "    if n != len(x) or n != len(m) or n != len(t):\n",
    "        raise ValueError(\"Inputs don't have the same number of observations\")\n",
    "\n",
    "    # Initialisation\n",
    "    (\n",
    "        p_x,  # P(T=1|X)\n",
    "        f_00x,  # f(M=0|T=0,X)\n",
    "        f_01x,  # f(M=0|T=1,X)\n",
    "        f_10x,  # f(M=1|T=0,X)\n",
    "        f_11x,  # f(M=1|T=1,X)\n",
    "        f_m0x,  # f(M|T=0,X)\n",
    "        f_m1x,  # f(M|T=1,X)\n",
    "        mu_t1,  # E[Y|T=1,M,X]\n",
    "        mu_t0,  # E[Y|T=0,M,X]\n",
    "        mu_t1_m1,  # E[Y|T=1,M=1,X]\n",
    "        mu_t1_m0,  # E[Y|T=1,M=0,X]\n",
    "        mu_t0_m1,  # E[Y|T=0,M=1,X]\n",
    "        mu_t0_m0,  # E[Y|T=0,M=0,X]\n",
    "        E_mu_t0_t0,  # E[E[Y|T=0,M,X]|T=0,X]\n",
    "        E_mu_t0_t1,  # E[E[Y|T=0,M,X]|T=1,X]\n",
    "        E_mu_t1_t0,  # E[E[Y|T=1,M,X]|T=0,X]\n",
    "        E_mu_t1_t1,  # E[E[Y|T=1,M,X]|T=1,X]\n",
    "    ) = [np.zeros(n) for _ in range(17)]\n",
    "    t0, m0 = np.zeros((n, 1)), np.zeros((n, 1))\n",
    "    t1, m1 = np.ones((n, 1)), np.ones((n, 1))\n",
    "    n_discarded = 0\n",
    "\n",
    "    if regularization:\n",
    "        alphas, cs = ALPHAS, ALPHAS\n",
    "    else:\n",
    "        alphas, cs = [0.0], [np.inf]\n",
    "\n",
    "    train_test_list = get_train_test_lists(crossfit, n)\n",
    "\n",
    "    # Cross-fitting loop\n",
    "    for train_index, test_index in train_test_list:\n",
    "        # Index declaration\n",
    "        test_ind = np.arange(len(test_index))\n",
    "        ind_t0 = t[test_index] == 0\n",
    "\n",
    "        y_reg, m_prob, p_x_clf  = get_regressions(regularization, interaction, forest, calibration)\n",
    "        y_reg.fit(\n",
    "            get_interactions(interaction, x, t, m)[train_index, :], y[train_index]\n",
    "        )\n",
    "        m_prob.fit(\n",
    "                get_interactions(interaction, t, x)[train_index, :], m[train_index]\n",
    "            )\n",
    "        p_x_clf.fit(\n",
    "                x[train_index, :], t[train_index]\n",
    "            )\n",
    "\n",
    "        # predict P(T=1|X)\n",
    "        p_x[test_index] = p_x_clf.predict_proba(x[test_index, :])[:, 1]\n",
    "\n",
    "        # predict f(M=m|T=t,X)\n",
    "        res = m_prob.predict_proba(get_interactions(interaction, t0, x)[test_index, :])\n",
    "        f_00x[test_index] = res[:, 0]\n",
    "        f_01x[test_index] = res[:, 1]\n",
    "        res = m_prob.predict_proba(get_interactions(interaction, t1, x)[test_index, :])\n",
    "        f_10x[test_index] = res[:, 0]\n",
    "        f_11x[test_index] = res[:, 1]\n",
    "\n",
    "        # predict f(M|T=t,X)\n",
    "        f_m0x[test_index] = m_prob.predict_proba(\n",
    "            get_interactions(interaction, t0, x)[test_index, :]\n",
    "        )[test_ind, m[test_index]]\n",
    "        f_m1x[test_index] = m_prob.predict_proba(\n",
    "            get_interactions(interaction, t1, x)[test_index, :]\n",
    "        )[test_ind, m[test_index]]\n",
    "\n",
    "        # predict E[Y|T=t,M,X]\n",
    "        mu_t1[test_index] = y_reg.predict(\n",
    "            get_interactions(interaction, x, t1, m)[test_index, :]\n",
    "        )\n",
    "        mu_t0[test_index] = y_reg.predict(\n",
    "            get_interactions(interaction, x, t0, m)[test_index, :]\n",
    "        )\n",
    "\n",
    "        # predict E[Y|T=t,M=m,X]\n",
    "        mu_t0_m0[test_index] = y_reg.predict(\n",
    "            get_interactions(interaction, x, t0, m0)[test_index, :]\n",
    "        )\n",
    "        mu_t0_m1[test_index] = y_reg.predict(\n",
    "            get_interactions(interaction, x, t0, m1)[test_index, :]\n",
    "        )\n",
    "        mu_t1_m1[test_index] = y_reg.predict(\n",
    "            get_interactions(interaction, x, t1, m1)[test_index, :]\n",
    "        )\n",
    "        mu_t1_m0[test_index] = y_reg.predict(\n",
    "            get_interactions(interaction, x, t1, m0)[test_index, :]\n",
    "        )\n",
    "\n",
    "        # E[E[Y|T=1,M=m,X]|T=t,X] model fitting\n",
    "        reg_y_t1m1_t0 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][ind_t0, :], mu_t1_m1[test_index][ind_t0]\n",
    "        )\n",
    "        reg_y_t1m0_t0 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][ind_t0, :], mu_t1_m0[test_index][ind_t0]\n",
    "        )\n",
    "        reg_y_t1m1_t1 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][~ind_t0, :], mu_t1_m1[test_index][~ind_t0]\n",
    "        )\n",
    "        reg_y_t1m0_t1 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][~ind_t0, :], mu_t1_m0[test_index][~ind_t0]\n",
    "        )\n",
    "\n",
    "        # predict E[E[Y|T=1,M=m,X]|T=t,X]\n",
    "        E_mu_t1_t0[test_index] = (\n",
    "            reg_y_t1m0_t0.predict(x[test_index, :]) * f_00x[test_index]\n",
    "            + reg_y_t1m1_t0.predict(x[test_index, :]) * f_01x[test_index]\n",
    "        )\n",
    "        E_mu_t1_t1[test_index] = (\n",
    "            reg_y_t1m0_t1.predict(x[test_index, :]) * f_10x[test_index]\n",
    "            + reg_y_t1m1_t1.predict(x[test_index, :]) * f_11x[test_index]\n",
    "        )\n",
    "\n",
    "        # E[E[Y|T=0,M=m,X]|T=t,X] model fitting\n",
    "        reg_y_t0m1_t0 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][ind_t0, :], mu_t0_m1[test_index][ind_t0]\n",
    "        )\n",
    "        reg_y_t0m0_t0 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][ind_t0, :], mu_t0_m0[test_index][ind_t0]\n",
    "        )\n",
    "        reg_y_t0m1_t1 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][~ind_t0, :], mu_t0_m1[test_index][~ind_t0]\n",
    "        )\n",
    "        reg_y_t0m0_t1 = RidgeCV(alphas=alphas, cv=CV_FOLDS).fit(\n",
    "            x[test_index, :][~ind_t0, :], mu_t0_m0[test_index][~ind_t0]\n",
    "        )\n",
    "\n",
    "        # predict E[E[Y|T=0,M=m,X]|T=t,X]\n",
    "        E_mu_t0_t0[test_index] = (\n",
    "            reg_y_t0m0_t0.predict(x[test_index, :]) * f_00x[test_index]\n",
    "            + reg_y_t0m1_t0.predict(x[test_index, :]) * f_01x[test_index]\n",
    "        )\n",
    "        E_mu_t0_t1[test_index] = (\n",
    "            reg_y_t0m0_t1.predict(x[test_index, :]) * f_10x[test_index]\n",
    "            + reg_y_t0m1_t1.predict(x[test_index, :]) * f_11x[test_index]\n",
    "        )\n",
    "\n",
    "    # trimming\n",
    "    p_x_trim = p_x != np.clip(p_x, trim, 1 - trim)\n",
    "    f_m0x_trim = f_m0x != np.clip(f_m0x, trim, 1 - trim)\n",
    "    f_m1x_trim = f_m1x != np.clip(f_m1x, trim, 1 - trim)\n",
    "    trimmed = p_x_trim + f_m0x_trim + f_m1x_trim\n",
    "\n",
    "    var_name = [\"t\", \"y\", \"p_x\", \"f_m0x\", \"f_m1x\", \"mu_t1\", \"mu_t0\"]\n",
    "    var_name += [\"E_mu_t1_t1\", \"E_mu_t0_t0\", \"E_mu_t1_t0\", \"E_mu_t0_t1\"]\n",
    "\n",
    "    for var in var_name:\n",
    "        exec(f\"{var} = {var}[~trimmed]\")\n",
    "    n_discarded += np.sum(trimmed)\n",
    "\n",
    "    # ytmt computing\n",
    "    y1m1 = t / p_x * (y - E_mu_t1_t1) + E_mu_t1_t1\n",
    "    y0m0 = (1 - t) / (1 - p_x) * (y - E_mu_t0_t0) + E_mu_t0_t0\n",
    "    y1m0 = (\n",
    "        (t / p_x) * (f_m0x / f_m1x) * (y - mu_t1)\n",
    "        + (1 - t) / (1 - p_x) * (mu_t1 - E_mu_t1_t0)\n",
    "        + E_mu_t1_t0\n",
    "    )\n",
    "    y0m1 = (\n",
    "        (1 - t) / (1 - p_x) * (f_m1x / f_m0x) * (y - mu_t0)\n",
    "        + t / p_x * (mu_t0 - E_mu_t0_t1)\n",
    "        + E_mu_t0_t1\n",
    "    )\n",
    "\n",
    "    # effects computing\n",
    "    total = np.mean(y1m1 - y0m0)\n",
    "    direct1 = np.mean(y1m1 - y0m1)\n",
    "    direct0 = np.mean(y1m0 - y0m0)\n",
    "    indirect1 = np.mean(y1m1 - y1m0)\n",
    "    indirect0 = np.mean(y0m1 - y0m0)\n",
    "\n",
    "    return total, direct1, direct0, indirect1, indirect0, n_discarded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf76a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a7bb5072",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "m is not binary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-d18483d21292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meffects_MR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiply_robust_efficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-126-098b296eaef3>\u001b[0m in \u001b[0;36mmultiply_robust_efficient\u001b[0;34m(y, t, m, x, interaction, forest, crossfit, trim, regularization, calibration, calib_method)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mdim_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdim_m\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"m is not binary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: m is not binary"
     ]
    }
   ],
   "source": [
    "effects_MR = multiply_robust_efficient(y, t, m, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2dabfd33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f67c3f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "03bed34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear coefficients\n",
      "Direct effects\n",
      "True theta1:[0.2], estimated theta1: 0.195\n",
      "True theta0:[0.2], estimated theta0: 0.195\n",
      "\\\n",
      "Indirect effects\n",
      "True delta1:[0.81], estimated delta1: 0.818\n",
      "True delta0:[0.81], estimated delta0: 0.818\n",
      "\\\n",
      "Total effect\n",
      "True tau:[1.01], estimated tau: 1.013\n"
     ]
    }
   ],
   "source": [
    "effects_linear = ols_mediation(y, t, m, x)\n",
    "\n",
    "tau_hat, theta_1_hat, theta_0_hat, delta_1_hat, delta_0_hat, n_non_trimmed = effects_linear\n",
    "print(\"Linear coefficients\")\n",
    "print(\"Direct effects\")\n",
    "print(\"True theta1:{}, estimated theta1: {}\".format(theta_1, round(theta_1_hat,3)))\n",
    "print(\"True theta0:{}, estimated theta0: {}\".format(theta_0, round(theta_0_hat,3)))\n",
    "print(\"\\\\\")\n",
    "print(\"Indirect effects\")\n",
    "print(\"True delta1:{}, estimated delta1: {}\".format(delta_1, round(delta_1_hat,3)))\n",
    "print(\"True delta0:{}, estimated delta0: {}\".format(delta_0, round(delta_0_hat,3)))\n",
    "print(\"\\\\\")\n",
    "print(\"Total effect\")\n",
    "print(\"True tau:{}, estimated tau: {}\".format(tau, round(tau_hat,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c2b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
